{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_file_path = '../word_embedding_pre_trained/glove_42B_300d_uncased/glove.42B.300d.txt'\n",
    "embedding_dimension = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_lines(fname):\n",
    "    result = 0\n",
    "    with open(fname, 'r') as f:\n",
    "        while f.buffer.readline():\n",
    "            result += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_and_embedding_matrices(file_path):\n",
    "    num_vocab = num_lines(file_path)\n",
    "    words = []\n",
    "    embedding = np.zeros(shape=(num_vocab, embedding_dimension), dtype=np.float32)\n",
    "    with open(embedding_file_path, 'r') as embedding_file:\n",
    "        pbar = tqdm.tqdm(total=num_vocab, file=sys.stdout)\n",
    "        for idx in range(num_vocab):\n",
    "            line = embedding_file.buffer.readline()\n",
    "            first_space_idx = line.find(b' ')\n",
    "            word = line[:first_space_idx].decode('utf-8')\n",
    "            vector_content = line[first_space_idx + 1:-1]\n",
    "            vector = np.array([np.float32(ele) for ele in vector_content.split()])\n",
    "\n",
    "            words.append(str(word))\n",
    "            embedding[idx] = vector\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "    return words, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1917494/1917494 [06:54<00:00, 4627.39it/s]\n"
     ]
    }
   ],
   "source": [
    "words, embedding = vocab_and_embedding_matrices(embedding_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_idx = dict()\n",
    "idx_to_word = dict()\n",
    "for idx, word in enumerate(words):\n",
    "    word_to_idx[word] = idx\n",
    "    idx_to_word[idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_for_word(word):\n",
    "    return embedding[word_to_idx[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vec):\n",
    "    embedding_norm = np.linalg.norm(embedding, axis=-1, keepdims=False)\n",
    "    return np.sum(embedding * vec, axis=-1)/(embedding_norm * np.linalg.norm(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analogy(word_a_to, word_b, word_c_to):\n",
    "    e_a, e_b, e_c = embedding_for_word(word_a_to), embedding_for_word(word_b), embedding_for_word(word_c_to)\n",
    "    a_minus_b = e_a - e_b\n",
    "    c_minus_embedding = e_c - embedding\n",
    "    for word in (word_a_to, word_b, word_c_to):\n",
    "        c_minus_embedding[word_to_idx[word]] = 100\n",
    "    embedding_norm = np.linalg.norm(c_minus_embedding, axis=-1, keepdims=False)\n",
    "    sim_mat = np.sum(c_minus_embedding * a_minus_b, axis=-1)/(embedding_norm * np.linalg.norm(a_minus_b))\n",
    "    most_similar_idx = np.argmax(sim_mat)\n",
    "    return idx_to_word[most_similar_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = 'sustainable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_embedding = embedding_for_word(word)\n",
    "sim_mat = cosine_similarity(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sim_mat[word_to_idx[word]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sustainability\n"
     ]
    }
   ],
   "source": [
    "most_similar_idx = np.argmax(sim_mat)\n",
    "print(idx_to_word[most_similar_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_pairs = (\n",
    "    ('good', 'better', 'fast'),\n",
    "    ('close', 'closer', 'far'),\n",
    "    ('fish', 'water', 'bird'),\n",
    "    ('beijing', 'china', 'paris'),\n",
    "    ('man', 'doctor', 'woman'),\n",
    "    ('man', 'brother', 'woman')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'good' ---> 'better': 'fast' ---> 'faster'.\n",
      "'close' ---> 'closer': 'far' ---> 'farther'.\n",
      "'fish' ---> 'water': 'bird' ---> 'air'.\n",
      "'beijing' ---> 'china': 'paris' ---> 'france'.\n",
      "'man' ---> 'doctor': 'woman' ---> 'physician'.\n",
      "'man' ---> 'brother': 'woman' ---> 'sister'.\n"
     ]
    }
   ],
   "source": [
    "for pair in word_pairs:\n",
    "    try:\n",
    "        a, b, c = pair\n",
    "        result = analogy(word_a_to=a, word_b=b, word_c_to=c)\n",
    "        print('\\'{0}\\' ---> \\'{1}\\': \\'{2}\\' ---> \\'{3}\\'.'.format(a, b, c, result))\n",
    "    except Exception:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
